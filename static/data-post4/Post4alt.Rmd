---
title: "Post 4"
output: html_notebook
---
We start loading the libraries.
```{r libraries, message=FALSE}
library(svDialogs)
library(tidyverse)
library(purrr)
library(foreign) 
library(RSQLite)
library(caret)
library(glmnet)
library(randomForest)
library(GGally)
library(tictoc)
library(DMwR)
library(ROSE)
library(broom)
```

ADD Health
Where are the data:
[link1](https://www.icpsr.umich.edu/icpsrweb/content/DSDR/add-health-data-guide.html)
[link2](https://www.cpc.unc.edu/projects/addhealth/documentation/ace/tool/topics)


```{r selected_var, eval=TRUE, include=FALSE, message=FALSE}
var_select <- scan("/Users/heverz/Documents/R_projects/muaydata/static/data-post4/variables.csv", what  = "list", sep = ",")
```
```{r show_selected, eval=TRUE, include=TRUE}
var_select
```


```{r getdata, eval=FALSE}
files <- list.files(path = "/Users/heverz/Documents/R_projects/DATASETS/W1-4",
                    include.dirs=FALSE,
                    full.names = TRUE)

w1_4 <- map(files, read.dta)

# get the varibles in var_select
w1_4_reduced <- map(w1_4, function (x) x[, colnames(x) %in% var_select])

#join not empty dataframes
toselect <- which(map(w1_4_reduced, function(x) ncol(x) > 0) == TRUE)
heal_data <- plyr::join_all(w1_4_reduced[toselect] , by = "AID", type = "inner")
heal_data$AID <- as.character(heal_data$AID)
```

```{r database, include=FALSE, eval=TRUE}
mydb <- dbConnect(RSQLite::SQLite(), "/Users/heverz/Documents/R_projects/muaydata/static/data-post4/heal_data.sqlite")

# dbWriteTable(mydb, "heal_data", heal_data)
# dbListTables(mydb)
heal_data <- as_tibble(tbl(mydb, "heal_data"))
glimpse(heal_data)
```


```{r factor}
heal_sub <- heal_data[,2:length(heal_data)]
heal_sub <- mutate_if(heal_sub, is.character, as.factor)
sum(is.na(heal_sub))
```

There are a lot of NA because the questionare was not submitted to a some parents
```{r count_NAs}

heal_sub[is.na(heal_sub$PA10),] %>% 
  select(PA34:PC49E_3) %>% 
  glimpse()
```

WE will remove those data

```{r removeNAs}
heal_sub_cl <- 
  heal_sub %>% 
  select(-c("S10")) %>% 
  select(1:48,51) %>% 
  na.omit()

names(heal_sub_cl)
#classifier_NA_insert
heal_sub_cl <- 
  heal_sub_cl %>% 
  mutate(H4TO117 = as.factor(str_extract(heal_sub_cl$H4TO117 , "[:alpha:]+")))

heal_sub_cl3 <- heal_sub_cl
```

# 2 Classes

Classifier of interest is H4T0117

```{r 2Classes}
heal_sub_cl$H4TO117[heal_sub_cl$H4TO117 == "Legitimate"] <- "No"

heal_sub_cl$H4TO117 <- droplevels(heal_sub_cl$H4TO117)

summary(heal_sub_cl$H4TO117)
```


The problem is that we have a very unballanced designed and therefore all the models tend to maximaze accuracy but not specificity (they say all not addicted). So we need to consider specificity as a metric too



# Models: 2 classes

## Resample
```{r resample}

set.seed(1512)
up_heal <- upSample(x = heal_sub_cl[, -ncol(heal_sub_cl)],
                     y = heal_sub_cl$H4TO117)                         
table(up_heal$Class) 
```


## TrainControl
```{r trainControl}
fitControl <- trainControl(method = "adaptive_cv",
                           number = 5, repeats = 5,
                           summaryFunction = twoClassSummary,
                           savePredictions = "final",
                            adaptive = list(min = 2,
                                            alpha = 0.05,
                                            method = "gls",
                                            complete = TRUE),
                           verboseIter = TRUE,
                           classProbs = TRUE)

```


## GLMNER MODEL
```{r mod1, eval=FALSE, include=TRUE}

mod_glmnet <- train(Class ~ ., 
              up_heal,
              method = "glmnet",
              tuneLength = 5,
              trControl = fitControl,
              na.action = na.omit,
              preProcess = c("nzv","corr", "pca")
              )

saveRDS(mod_glmnet, "mod_glmnet.RDS")
mod_glmnet <- readRDS("mod_glmnet.RDS")
print(mod_glmnet)
```

```{r preprocessing}
str(mod_glmnet)
mod_glmnet$preProcess


mod_glmnet$preProcess$method$remove
```


```{r eval_glmnet_print}
print(mod_glmnet)
```
```{r eval_glmnet_matrix}
confM<- confusionMatrix(mod_glmnet)
confM
```


```{r eval_glmnet_graphs}

mod_glmnet$resample %>% 
  as.data.frame() %>% 
  gather("metric", "value", 1:3) %>% 
  group_by(metric) %>% 
  summarise(mean = mean(value), stdev = sd(value)) %>% 
  ggplot(aes(y = mean, x = metric, col = metric, fill = metric)) +
    geom_col() +
    geom_errorbar(aes(ymin = mean - stdev, ymax =  mean + stdev), width = 0.2) +
    scale_y_continuous(limits = c(0,1)) +
    geom_label(aes(y = 0.8, label = round(mean,2)), fill = "white") +
  theme()


# resample_stats <- thresholder(mod_glmnet, 
#                               threshold = seq(.5, 1, by = 0.05), 
#                               final = TRUE)
# 
# 
# plot(mod_glmnet, metric = "accuracy")
# ggplot(resample_stats, aes(x = prob_threshold, y = Sensitivity)) + 
#  geom_point() + 
#  geom_point(aes(y = Specificity), col = "red")

```



## RANDOM FOREST
```{r mod2, eval=FALSE, include=TRUE}

mod_ranger <- train(Class ~ ., 
              up_heal,
              method = "ranger",
              metric = "ROC",
              tuneLength = 5,
              trControl = fitControl,
              preProcess = c("nzv","corr", "pca"),
              na.action = na.omit,
              verbose = TRUE
              )

# 1145.438 sec elapsed

saveRDS(mod_ranger, "mod_ranger.RDS")
mod_ranger <- readRDS("mod_ranger.RDS")

```



```{r compare}

model_list <- list( glmnet = mod_glmnet,
                    rf = mod_ranger)

resamps <- resamples(model_list)

saveRDS(resamps, "resamps.RDS")
resamps <- readRDS("resamps.RDS")

ggplot(resamps, metric = "ROC") 
 

ggplot(mod_ranger, metric = "Sens")

mean(resamps$values$`rf~Sens`)
```


# Model: 3 classes

```{r 3_resample}
get.seed(1512)
up_heal3 <- upSample(x = heal_sub_cl3[, -ncol(heal_sub_cl3)],
                     y = heal_sub_cl3$H4TO117)                         
table(up_heal$Class) 
```
```{r trainControl3}

fitControl3 <- trainControl(method = "adaptive_cv",
                           number = 5, repeats = 5,
                           summaryFunction = multiClassSummary,
                           savePredictions = "final",
                            adaptive = list(min = 2,
                                            alpha = 0.05,
                                            method = "gls",
                                            complete = TRUE),
                           verboseIter = TRUE,
                           classProbs = TRUE)

mod_ranger3 <- train(Class ~ ., 
              up_heal3,
              method = "ranger",
              metric = "ROC",
              tuneLength = 5,
              trControl = fitControl3,
              preProcess = c("nzv","corr", "pca"),
              na.action = na.omit,
              verbose = TRUE
              )

print(mod_ranger3)

confusionMatrix(mod_ranger3)
```

```{r devbug_ggplot}


getAnywhere("ggplot")

getAnywhere("ggplot.resamples")


ggplot(resamps)



ttest <- try(t.test(x$value, conf.level = cl), silent = TRUE)
# Error in t.test.default(plotData$`rf~ROC`$value, conf.level = 0.95) : 
#   data are essentially constant  
rep(NA, 3)
  

plotData <- list("Model" = "rf~ROC")

x <- list(value = list(rep(1,10)))
cl = "0.095"
t.test(rep(1,10), conf.level = 0.95)
     
plotData$`rf~ROC`$value

x <- rep(1, 10)

typeof(x)
```

