---
title: "Post 4"
output: html_notebook
---
We start loading the libraries.
```{r libraries, message=FALSE}
library(svDialogs)
library(tidyverse)
library(purrr)
library(foreign) 
library(RSQLite)
library(caret)
library(glmnet)
library(randomForest)
library(GGally)
library(tictoc)
library(DMwR)
library(ROSE)
```

ADD Health
Where are the data:
[link1](https://www.icpsr.umich.edu/icpsrweb/content/DSDR/add-health-data-guide.html)
[link2](https://www.cpc.unc.edu/projects/addhealth/documentation/ace/tool/topics)

method = "rborist"


```{r getdata, eval=FALSE}

files <- list.files(path = "/Users/heverz/Documents/R_projects/DATASETS/W1-4",
                    include.dirs=FALSE,
                    full.names = TRUE)

w1_4 <- map(files, read.dta)

var_select <- scan("/Users/heverz/Documents/R_projects/muaydata/static/data-post4/variables.csv", what  = "list", sep = ",")

# get the varibles in var_select
w1_4_reduced <- map(w1_4, function (x) x[, colnames(x) %in% var_select])

#join not empty dataframes
toselect <- which(map(w1_4_reduced, function(x) ncol(x) > 0) == TRUE)
heal_data <- plyr::join_all(w1_4_reduced[toselect] , by = "AID", type = "inner")
heal_data$AID <- as.character(heal_data$AID)
```

```{r database, include=FALSE, eval=TRUE}
mydb <- dbConnect(RSQLite::SQLite(), "/Users/heverz/Documents/R_projects/muaydata/static/data-post4/heal_data.sqlite")


# dbWriteTable(mydb, "heal_data", heal_data)
# dbListTables(mydb)
heal_data <- as_tibble(tbl(mydb, "heal_data"))
```


```{r factor}
heal_sub <- heal_data[,2:length(heal_data)]
heal_sub <- mutate_if(heal_sub, is.character, as.factor)
sum(is.na(heal_sub))
```

There are a lot of NA because the questionare was not submitted to a some parents
```{r count_NAs}

heal_sub[is.na(heal_sub$PA10),]
```

Parent questionare is an important part of our analysis we will remove those NAs

```{r removeNAs}
heal_sub_cl <- 
  heal_sub %>% 
  select(-c("S10")) %>% 
  select(1:48,51) %>% 
  na.omit()

names(heal_sub_cl)
#classifier_NA_insert
heal_sub_cl <- 
  heal_sub_cl %>% 
  mutate(H4TO117 = as.factor(str_extract(heal_sub_cl$H4TO117 , "[:alpha:]+")))

heal_sub_cl3 <- heal_sub_cl
```

# 2 Classes

```{r 2Classes}
heal_sub_cl$H4TO117[heal_sub_cl$H4TO117 == "Legitimate"] <- "No"

heal_sub_cl$H4TO117 <- droplevels(heal_sub_cl$H4TO117)

summary(heal_sub_cl$H4TO117)
```

https://www.analyticsvidhya.com/blog/2016/12/practical-guide-to-implement-machine-learning-with-caret-package-in-r-with-practice-problem/



https://topepo.github.io/caret/available-models.html

The problem is that we have a very unballanced designed and therefore all the models tend to maximaze accuracy but not specificity (they say all not addicted). So we need to consider specificity as a metric too



# Models: 2 classes
```{r resample}

set.seed(1512)
up_heal <- upSample(x = heal_sub_cl[, -ncol(heal_sub_cl)],
                     y = heal_sub_cl$H4TO117)                         
table(up_heal$Class) 
```


```{r trainControl}
fitControl <- trainControl(method = "adaptive_cv",
                           number = 5, repeats = 5,
                           summaryFunction = twoClassSummary,
                           savePredictions = "final",
                            adaptive = list(min = 2,
                                            alpha = 0.05,
                                            method = "gls",
                                            complete = TRUE),
                           verboseIter = TRUE,
                           classProbs = TRUE)

```






```{r mod1, eval=FALSE, include=TRUE}

mod_glmnet <- train(Class ~ ., 
              up_heal,
              method = "glmnet",
              tuneLength = 5,
              trControl = fitControl,
              na.action = na.omit,
              preProcess = c("nzv","corr", "pca")
              )

saveRDS(mod_glmnet, "mod_glmnet.RDS")
mod_glmnet <- readRDS("mod_glmnet.RDS")
print(mod_glmnet)
```

```{r eval_mod_glmnet}

class(coef(mod_glmnet$finalModel))

plot(mod_glmnet)
confusionMatrix(mod_glmnet)
resample_stats <- thresholder(mod_glmnet, 
                              threshold = seq(.5, 1, by = 0.05), 
                              final = TRUE)


ggplot(resample_stats, aes(x = prob_threshold, y = Sensitivity)) + 
 geom_point() + 
 geom_point(aes(y = Specificity), col = "red")

```


```{r mod2, eval=FALSE, include=TRUE}

mod_ranger <- train(Class ~ ., 
              up_heal,
              method = "ranger",
              metric = "ROC",
              tuneLength = 5,
              trControl = fitControl,
              preProcess = c("nzv","corr", "pca"),
              na.action = na.omit,
              verbose = TRUE
              )

# 1145.438 sec elapsed

saveRDS(mod_ranger, "mod_ranger.RDS")
mod_ranger <- readRDS("mod_ranger.RDS")

```



```{r compare}

model_list <- list( glmnet = mod_glmnet,
                    rf = mod_ranger)

resamps <- resamples(model_list)

saveRDS(resamps, "resamps.RDS")

ggplot(resamps, metric = "ROC") 
 

ggplot(mod_ranger, metric = "Sens")

mean(resamps$values$`rf~Sens`)
```


```{r}
resamps$values

```
# Model: 3 classes

```{r 3_resample}
get.seed(1512)
up_heal3 <- upSample(x = heal_sub_cl3[, -ncol(heal_sub_cl3)],
                     y = heal_sub_cl3$H4TO117)                         
table(up_heal$Class) 
```
```{r trainControl3}

fitControl3 <- trainControl(method = "adaptive_cv",
                           number = 5, repeats = 5,
                           summaryFunction = multiClassSummary,
                           savePredictions = "final",
                            adaptive = list(min = 2,
                                            alpha = 0.05,
                                            method = "gls",
                                            complete = TRUE),
                           verboseIter = TRUE,
                           classProbs = TRUE)

mod_ranger3 <- train(Class ~ ., 
              up_heal3,
              method = "ranger",
              metric = "ROC",
              tuneLength = 5,
              trControl = fitControl3,
              preProcess = c("nzv","corr", "pca"),
              na.action = na.omit,
              verbose = TRUE
              )

print(mod_ranger3)

confusionMatrix(mod_ranger3)
```

```{r devbug_ggplot}


getAnywhere("ggplot")

getAnywhere("ggplot.resamples")


plotData <- tibble("value" = rep(1,10), "Model" = rep("rf~ROC", 10))  
t.test(plotData$`rf~ROC`$value, conf.level = 0.95)

ttest <- try(t.test(x$value, conf.level = cl), silent = TRUE)
# Error in t.test.default(plotData$`rf~ROC`$value, conf.level = 0.95) : 
#   data are essentially constant  
rep(NA, 3)
  




```

